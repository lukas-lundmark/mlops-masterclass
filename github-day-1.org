#+title: GitHub Integration - Day 1
#+author: luklun


* Getting Familiar with GitHub Actions
If you are unfamiliar with CI/CD pipelines you can start simple. If you started from the project template you should already have a project with a GitHub repo setup. It should also contain a .github folder. Create a new folder called workflows in the .github. This folder will store the GitHub Action workflows.

Open your text editor of choice and create a file named hello-world.yaml. Write the following

#+begin_src yaml
# .github/workflows/hello-world.yaml
name: Hello World

on:
  push:
    branches: [main]

jobs:
  hello-world-job:
    name: Hello World # Will be displayed when overviewing the jobs
    runs-on: ubuntu-latest # The OS of the runner virtual machine
    steps: # The list of steps in this job
      - name: Say Hello # This will be displayed when this step is exectued
        run: echo "HELLO WORLD" # The shell action to perform
#+end_src

This is a simple GitHub Workflow that will be triggered on pushes to the main branch. It starts a single job running on an ubuntu runner. The job has one single step that echoes HELLO WORLD to the console.

Commit and push to the main branch.
#+begin_src bash
git add .github/workflows
git commit -m "Adding Hello World"
git push origin main
#+end_src

(I am gonna assume that you are atleast somewhat familiar with how git works)

Go to your repository page on GitHub and click the Action tab. You should see a new workflow run has started. Click on the workflow, and look at the different steps. One of them should have written HELLO WORLD to the console. Note that you didn't need to do anything other than creating a valid workflow file for a workflow to be created and started.

If the workflow file is invalid, GitHub Action will notify you and point out where in your workflow definition you have an error.

** Building Docker Images Automatically
Since we want to be able to run some Azure ML code in our CI/CD pipelines, we need to assure that our runner has all the required dependencies. There are multiple ways to do this, one is to download the dependencies in every job. However, this is brittle, hard to maintain, and also time-consuming during runs. Instead, we can build our own Docker image, push it to a container registry and use it as the container for our runner.

GitHub now offers its own Container Registry, called GitHub Container Registry (GHCR). Each account can push containers to its own registry, which is located at ghcr.io/{account}. You use the same credentials to access your registry as for your GitHub account. The most convenient way to get access to your registry is via a Personal Access Token.

Go to Developer Settings on your GitHub profile. Select personal access token, and generate a new one. You want the Token to have read & write access to packages (packages are GitHub's term for published Docker Images). Create the token, and save it somewhere that you don't lose it.

First, make sure that you can log in to your container registry. Open a terminal and run

#+begin_src bash
export CR_PAT=<your-new-token>
echo $CR_PAT | docker login ghcr.io --username <your-github-name> --password-stdin
#+end_src
It should say "login successfull".

Now, if you haven't already done so, copy the *environment_setup* folder from the workshop repo and add it to your repo. Try and see if you can build the docker locally first, and see if you can push it to your Container Repo

#+begin_src bash
docker build --platform linux/amd64 -t ghcr.io/<your-github-user>/mlopsci:latest environment_setup/
#+end_src

This can take up to five or six minutes, so you can read ahead if you want. When the docker image is built you can see if you can push it to your container registry. You should already be logged in so you should just be able to push

#+begin_src bash
docker push ghcr.io/<your-github-user>/mlopsci:latest
#+end_src

Check on your GitHub profile page, under the packages tab to see if you have a new package there. You can delete it if you want. If all that works, we are in a good position to automate the build of our CI container.

Remember that Personal Access Token (you did save it, right?). Create a new GitHub secret in your repository. Go to the project settings, secrets, and action. Give it the name CR_PAT and past the in the access token.

Now, we need to create a new workflow that will need to perform three different steps. It will need to checkout the current repo, it needs to login to GHCR, and it needs to build and push the image. Fortunately for us, there exist prebuilt GitHub Actions for all these steps. Below you can see an example of how this can be done

#+begin_src yaml
name: Building Docker
on:
  push:
    branches: [main]
  workflow_dispatch:
jobs:
  build-and-push-docker-image:
    name: Build Docker image and push to repositories
    runs-on: ubuntu-latest
      steps:
        - name: Checkout Code
          uses: actions/checkout@v2

        - name: Login to Github Packages
          uses: docker/login-action@v1
          with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.CR_PAT }}

        - name: Build and Push
          uses: docker/build-push-action@v2
          with:
          context: ./environment_setup/
          tags: ghcr.io/${{github.actor}}/mlopscli:latest
#+end_src

Add this job and see if your container builds and that you get a new package in your account.




*** Improvements
There is no need to rebuild the image every time we commit to main. Instead, we should only rebuid if something related to the environment_setup directory changes.

Add the paths defintion to the *on* key like this:
#+begin_src yaml
on:
  push:
    branches: [main]
    paths:
      - 'environment_setup/**'
  workflow_dispatch:
#+end_src

The second improvement would be to add more tags to the image. Right now, we overwrite the previous image with a new one, which isn't good for reproducibility. A fix is to use two tags when building. One tag that uses the current commit hash, and one that uses the latest. This way, you know which build generated a certain image. In this workshop, it might be overkill, so try it if you want to

#+begin_src yaml
tags: |
    "ghcr.io/${{github.actor}}/mlopsci:latest"
    "ghcr.io/${{github.actor}}/mlopsci:${{github.sha}}"
#+end_src

** Connecting to Azure
The next step is to run some Azure ML code in our Pipeline. In order for GitHub Action to interact with your AML workspace you need to give it access. The recommended way to give an automated process acccess to Azure resources is with a *Service Principal*. A Service Principle is a form of Azure account that doesn't belong to any user, and can instead by scripts and applications. SP accounts use the same Role-Based Authenticaction as all other accounts, and you can therefore make sure to only give the SP the minimal required roles for completing its task.

We will create a Service Principal for Azure ML using the Azure CLI. First, login to your Azure account using the Azure CLI src_bash{az login}. Set the default subscription if you haven't already done so: src_bash{az account set -s your-subscription-id}. You can list your subscriptions using src_bash{az account list}.

Then, create a service principle with role based authentication and sdk authentication, and give it access to the resource group of your ML Workspace.

In total, run the following in your terminal
#+begin_src bash
az login
# List your accounts
az account list
# Set a default account if you have more than one
az account set -s your-subscription-id
# Create a service principle
az ad sp create-for-rbac --sdk-auth --name a-cool-name-for-the-sp --role contributor --scopes /subscriptions/<your-subscription-id>/resourceGroups/<resource-group-of-your-workspace>
#+end_src

This will output a json string in the terminal which defines the Service Principle. Copy this json string and save it somewhere that you don't lose it. Create a new secret in your repostiotory called *AZURE_CREDENTIALS* and paste the entire json string into it. We will use it in just a few steps.

Now, the environment we built already contains both Azure CLI and the Azure ML Extension. So what we need is a way to run in our docker image and log in using the Service Principle we created in our jobs.

First of all, we need to add a dependency on the docker build job using ~needs~. This will make this job wait for the build job to finish

#+begin_src yaml
connect-to-azure:
  needs: build-and-push-docker-image
  name: Connect to Azure
  runs-on: ubuntu-latest
#+end_src

Second, we need to use the container we built. We can reference our container like this

#+begin_src yaml
...
container:
  image: ghcr.io/<your-username>/<mame-of-image>:latest
  credentials:
    username: ${{ github.actor }}
    password: ${{ secrets.CR_PAT }}
#+end_src
Unfortunately, GitHub Action doesn't allow you to do dynamic reference to docker image you want to use. So we need to hard-code it for now. The combination of the runs-on and the container field means that the job will run on a Ubuntu Runner using our container.

You can then login to Azure using the following Action using the service principle definition we created before secret
#+begin_src yaml
- name: Authenticate with Azure
  uses: azure/login@v1
  with:
    creds: ${{ secrets.AZURE_CREDENTIALS }}
#+end_src

Your Azure ML workspace can be uniquely identified from three parameters: the subscription id, resource group, and workspace name. Your Service Principle now has access to the one subscription you gave it, but we should also set the default resource group and workspace name so we don't have to manually set these parameters in all subsequent calls. You can configure Azure CLI like this

#+begin_src bash
az configure -â€“defaults group=<resource-gruop>
az configure --defaults workspace=<workspace>
#+end_src

We need to set the following environment variables

Add an environment variable definition at the top of the workflow file
#+begin_src yaml
env:
  RESOURCE_GROUP="<your-resource-group>"
  WORKSPACE_NAME="<workspace-name>"
#+end_src

And then create a step
#+begin_src yaml
- name: Set AZ Configs
  run: |
    az configure --defaults group='${{ env.RESOURCE_GROUP }}'
    az configure --defaults workspace='${{ env.WORKSPACE }}'
#+end_src

Similarly, we need to have a workspace config in our root directory for some as our local setup. You could, of course, add this file to your repository, but that seems ill-adviced.

This small little script allows you to recreate the workspace configuration, given two environment variables RG and WORKSPACE

#+begin_src bash
SUBSCRIPTION=$(az account list --query '[0].id' --output tsv)
# Create a config object from our parameters using jq
JSON_STRING=$(jq -n \
    --arg sub $SUBSCRIPTION \
    --arg rg $RG \
    --arg ws $WORKSPACE \
    '{subscription_id: $sub, resource_group: $rg, workspace_name: $ws}')
# Write the json string to the current repo
echo -e $JSON_STRING >> $PWD/config.json
#+end_src

However, at this point, this is becoming a lot of boiler plate to just connect to Azure ML. We can make all of this necessary setup by creating our own Github action. Local actions are made by adding an *actions* folder in the .github directory. There is already a predefined action for this in your tenpmlate. The following code defines an action that takes the Azure Credentials, Resource Group, and Workspace name and performs the steps we outlined earlier.

#+begin_src yaml
name: 'aml_log'
description: 'Prepare Azure ML'

# Defines the inputs
inputs:
  AZURE_CREDENTIALS:
    description: "Azure Credential Object"
    required: true
  RESOURCE_GROUP:
    description: "Name of ML Resource Group"
    required: true
  WORKSPACE:
    description: "Name of ML workspace"
    required: true

runs:
  using: "composite" # This action is a composite of other actions
  steps:
    - name: Authenticate with Azure
      uses: azure/login@v1
      with:
        creds: ${{ inputs.AZURE_CREDENTIALS }}

    # Actions need to define which shell to use
    - name: Set AZ Configs
      shell: bash
      run: |
        az configure --defaults group='${{ inputs.RESOURCE_GROUP }}'
        az configure --defaults workspace='${{ inputs.WORKSPACE }}'

    - name: Produce AML Config
      shell: bash
      run: |
        # We assume this SP only has one subscription
        SUBSCRIPTION=$(az account list --query [0].id --output tsv)
        # Create a config object from our parameters using jq
        JSON_STRING=$(jq -n \
            --arg sub $SUBSCRIPTION \
            --arg rg ${{ inputs.RESOURCE_GROUP }} \
            --arg ws ${{ inputs.WORKSPACE }} \
            '{subscription_id: $sub, resource_group: $rg, workspace_name: $ws}')
        # Write the json string to the current repo
        echo -e $JSON_STRING >> $PWD/config.json
#+end_src

This will log in to your Azure account. It will set the AZ CLI defaults, and it will create a workspace config.json file for you. Note that this requires the jq cli utility, which is already installed by default in our CI/CD Image.

At the start of each Job that requires Azure ML, we simply run to set up our Azure ML environment. What we have done here is to reduce the boilerplate by making a reusable action component.

#+begin_src yaml
steps:
  # We need to checkout the code to use loca actions
  - name: Checkout Code
    uses: actions/checkout@v2

  - name: AML Login
    uses: ./.github/actions/aml_login
    with:
      AZURE_CREDENTIALS: ${{ secrets.AZURE_CREDENTIALS }}
      RESOURCE_GROUP: ${{ env.RESOURCE_GROUP }}
      WORKSPACE: ${{ env.WORKSPACE }}
#+end_src

Actions are a convenient way to reduce code duplication (although I think Azure DevOps's job templates are far superior).

Create yet another workflow now that simple connects to Azure and runs the pipeline you created during the last day.
It should contain a job that looks like this

#+begin_src yaml
- name: Run Pipeline
  # run: python -m ml_pipelines.build_train_pipeline
  run: python -m ml_pipelines.run_pipeline.py
#+end_src

For convinience, you should give it a workflow_dispatch trigger. Such that you can trigger it manually from GitHub.

#+begin_src yaml
on: workflow_dispatch
#+end_src

Go to the Actions tab in your repo, click on this workflow (it should have either the name you gave it or the path to the workflow file).  Click on the workflow and then click the Run workflow button

** Step Outputs
You can set the output of a step, such that later steps in the job can reference that information. For example, it might be useful for later step in the process to know if the pipeline finished or if it was cancelled.

The syntax looks like this
#+begin_src yaml
- name: step name
  id: unique-id
  run |
    # Do something here
    # Do something else
    # Set the output
    echo ::set-output name=<name-of-output>::<value-of-output>
#+end_src

You can then reference it as
steps.unique-id.outputs.<name-of-output>

Update your pipeline run script to output the final status of the pipeline run to a file. And then save the result of that file as an output of the step
Then, make if so that if the status was "Finished". You dispatch
